{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6rBTcH41KytE"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports ##"
      ],
      "metadata": {
        "id": "fnvqF-2oOEMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eSkWVJh7Mf7-"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import words\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation ##"
      ],
      "metadata": {
        "id": "6rBTcH41KytE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIgA8vFsHXPK",
        "outputId": "1033172a-a914-4c40-8439-6939bbbce922"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"kaggle_RC_2019-05.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "JKnffp7UHfqu",
        "outputId": "f93286dc-68ca-4ae0-faa7-5d899896312d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       subreddit                                               body  \\\n",
              "0  gameofthrones  Your submission has been automatically removed...   \n",
              "1            aww  Dont squeeze her with you massive hand, you me...   \n",
              "2         gaming  It's pretty well known and it was a paid produ...   \n",
              "3           news  You know we have laws against that currently c...   \n",
              "4       politics  Yes, there is a difference between gentle supp...   \n",
              "\n",
              "   controversiality  score  \n",
              "0                 0      1  \n",
              "1                 0     19  \n",
              "2                 0      3  \n",
              "3                 0     10  \n",
              "4                 0      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89531363-a961-4fda-ab23-62def4706a43\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gameofthrones</td>\n",
              "      <td>Your submission has been automatically removed...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aww</td>\n",
              "      <td>Dont squeeze her with you massive hand, you me...</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gaming</td>\n",
              "      <td>It's pretty well known and it was a paid produ...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>news</td>\n",
              "      <td>You know we have laws against that currently c...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>politics</td>\n",
              "      <td>Yes, there is a difference between gentle supp...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89531363-a961-4fda-ab23-62def4706a43')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89531363-a961-4fda-ab23-62def4706a43 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89531363-a961-4fda-ab23-62def4706a43');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09fab179-e8e1-40bd-bf21-1091b4e54369\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09fab179-e8e1-40bd-bf21-1091b4e54369')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09fab179-e8e1-40bd-bf21-1091b4e54369 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove controversial statements\n",
        "data = data[data[\"controversiality\"] != 1]\n",
        "#data = data[[\"body\"]]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqxnaiArHfog",
        "outputId": "411d7772-d0c0-4d59-ed2a-e8654456712a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       subreddit                                               body  \\\n",
            "0  gameofthrones  Your submission has been automatically removed...   \n",
            "1            aww  Dont squeeze her with you massive hand, you me...   \n",
            "2         gaming  It's pretty well known and it was a paid produ...   \n",
            "3           news  You know we have laws against that currently c...   \n",
            "4       politics  Yes, there is a difference between gentle supp...   \n",
            "\n",
            "   controversiality  score  \n",
            "0                 0      1  \n",
            "1                 0     19  \n",
            "2                 0      3  \n",
            "3                 0     10  \n",
            "4                 0      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = set(words.words())\n",
        "\n",
        "def clean_text(string):\n",
        "  list_ = string.split(\" \")\n",
        "  # convert all to lower case except special case: \"I\"\n",
        "  lower_cases = [word.lower() for word in list_ if word != \"I\"]\n",
        "  # only include words that appear in the english language\n",
        "  valid_words = [word for word in lower_cases if word in corpus]\n",
        "  return valid_words"
      ],
      "metadata": {
        "id": "rT5QywFOHfmR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['body'] = data['body'].apply(lambda x: clean_text(x))\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU46CDM7HlgF",
        "outputId": "31a4c452-0c44-4fa2-e0a5-1198596ca7b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       subreddit                                               body  \\\n",
            "0  gameofthrones  [your, submission, been, automatically, remove...   \n",
            "1            aww  [dont, squeeze, her, with, you, massive, you, ...   \n",
            "2         gaming  [pretty, well, known, and, it, was, a, product...   \n",
            "3           news  [you, know, we, have, against, that, currently...   \n",
            "4       politics  [there, is, a, difference, between, gentle, su...   \n",
            "\n",
            "   controversiality  score  \n",
            "0                 0      1  \n",
            "1                 0     19  \n",
            "2                 0      3  \n",
            "3                 0     10  \n",
            "4                 0      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_dataset_words = []\n",
        "def compile_all_words(word_list):\n",
        "  all_dataset_words.extend(word_list)\n",
        "  return word_list\n",
        "\n",
        "data['body'] = data['body'].apply(compile_all_words)\n",
        "\n",
        "all_unique_words = set(all_dataset_words)"
      ],
      "metadata": {
        "id": "KsEqx6mWHldj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_unique_words = len(all_unique_words)\n",
        "num_unique_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp2ZM6XtHla_",
        "outputId": "20503ba0-ace3-4fd8-8552-beb410ee8fa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30857"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of words to their numbers and vice versa\n",
        "string_to_int = {s: i for i, s in enumerate(all_unique_words)}\n",
        "int_to_string = {i: s for s, i in string_to_int.items()}"
      ],
      "metadata": {
        "id": "oRwCf7xnH3_M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build training data and labels\n",
        "\n",
        "block_size = 3  # trigram model\n",
        "X, y = [], []\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "  word_list = row['body']\n",
        "  for i in range(len(word_list) - block_size + 1):\n",
        "    context = word_list[i:i + block_size - 1]  # context (2 words for trigram)\n",
        "    target = word_list[i + block_size - 1]  # target (3rd word in trigram)\n",
        "\n",
        "    # Convert context and target to integer representation\n",
        "    context_indices = [string_to_int[word] for word in context]\n",
        "    target_index = string_to_int[target]\n",
        "\n",
        "    X.append(context_indices)\n",
        "    y.append(target_index)"
      ],
      "metadata": {
        "id": "iCWrC1KUH380"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X)\n",
        "y = torch.tensor(y)"
      ],
      "metadata": {
        "id": "pLR4q-XmH36W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGEZEJHyIF0T",
        "outputId": "192582d2-d9a8-449a-dbf8-955f6f048432"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([17779504, 2]), torch.Size([17779504]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create embedding tensor -> 90 unique words will be embedded each into 10 values\n",
        "C = torch.randn((num_unique_words, 10))"
      ],
      "metadata": {
        "id": "LTdBemGFIFvm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IANHaUQfIMZ1",
        "outputId": "c31f9832-6a7b-43f9-df23-77ed60bc3785"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30857, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lookup of embeddings for every context tensor in X\n",
        "emb = C[X]\n",
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aPyrkonIMXV",
        "outputId": "76208a9b-f751-46e4-a3fa-9def8a787d55"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([17779504, 2, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split into Training and Testing ##"
      ],
      "metadata": {
        "id": "iNe9xfkZKvgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(X)\n",
        "reduced_size = n_samples // 10000  # Reduce data size\n",
        "indices = torch.randperm(n_samples)[:reduced_size]\n",
        "X_reduced = X[indices]\n",
        "y_reduced = y[indices]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_reduced, y_reduced, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training data: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Testing data: X_test={X_val.shape}, y_test={y_val.shape}\")\n",
        "print(f\"Testing data: X_test={X_test.shape}, y_test={y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUeKvrceIMVN",
        "outputId": "5b5756c2-15cb-497d-a330-8380055f6838"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: X_train=torch.Size([1136, 2]), y_train=torch.Size([1136])\n",
            "Testing data: X_test=torch.Size([285, 2]), y_test=torch.Size([285])\n",
            "Testing data: X_test=torch.Size([356, 2]), y_test=torch.Size([356])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Device, Move Data to Device ##"
      ],
      "metadata": {
        "id": "O3KwwGBPOGuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Currently using {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nVZZe1KN7eY",
        "outputId": "648c420b-0666-495d-fa4e-e1c01949fdd6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.to(device)\n",
        "X_val = X_val.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_val = y_val.to(device)\n",
        "y_test = y_test.to(device)"
      ],
      "metadata": {
        "id": "teF7m2hrOCwd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbstiG33Rlhf",
        "outputId": "8e7b4506-6bb3-41f7-d778-81c145e12fa8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1136, 2]), torch.Size([285, 2]), torch.Size([356, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape, y_val.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cOSyRH3GLM1",
        "outputId": "ba9d5b42-3302-4514-c450-640620722aa1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1136]), torch.Size([285]), torch.Size([356]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Trigram Model ##"
      ],
      "metadata": {
        "id": "hhIPtFTuOJ4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrigramModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, block_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.C = nn.Embedding(vocab_size, embedding_dim)  # Embedding layer\n",
        "    self.linear_stack = nn.Sequential(\n",
        "      nn.Linear(block_size * embedding_dim, hidden_size),\n",
        "      nn.Linear(hidden_size, hidden_size),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(hidden_size, vocab_size)  # Output layer\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    emb = self.C(X)  # Convert indices to embeddings\n",
        "    emb = emb.view(emb.shape[0], -1)\n",
        "    logits = self.linear_stack(emb)  # Pass through the linear stack\n",
        "    return logits"
      ],
      "metadata": {
        "id": "pmQhhZFhM3bk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TrigramModel(num_unique_words, 10, 2, 300)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJTKt08dOcCS",
        "outputId": "449cab23-4ec9-4874-df8c-b952b0f3e9fc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrigramModel(\n",
              "  (C): Embedding(30857, 10)\n",
              "  (linear_stack): Sequential(\n",
              "    (0): Linear(in_features=20, out_features=300, bias=True)\n",
              "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
              "    (2): Tanh()\n",
              "    (3): Linear(in_features=300, out_features=30857, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training ##"
      ],
      "metadata": {
        "id": "7TYo72ClP52C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "# Hyperparameters\n",
        "embedding_dim = 10\n",
        "block_size = 2  # Trigram context size\n",
        "hidden_size = 300\n",
        "vocab_size = num_unique_words\n",
        "epochs = 1000\n",
        "lr = 0.01\n",
        "\n",
        "def train_model(embedding_dim, block_size, hidden_size, vocab_size, epochs=1000, lr=0.01):\n",
        "  # Initialize model, loss function, and optimizer\n",
        "  model = TrigramModel(vocab_size, embedding_dim, block_size, hidden_size)\n",
        "  model.to(device)\n",
        "  loss_fun = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
        "\n",
        "  # Track losses\n",
        "  epoch_count = []\n",
        "  loss_values = []\n",
        "  test_loss_values = []\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    y_pred = model(X_train)\n",
        "    loss = loss_fun(y_pred, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_pred = model(X_val)\n",
        "      test_loss = loss_fun(test_pred, y_val)\n",
        "\n",
        "    # Log metrics\n",
        "    if epoch % 10 == 0:\n",
        "      epoch_count.append(epoch)\n",
        "      loss_values.append(loss.item())\n",
        "      test_loss_values.append(test_loss.item())\n",
        "      print(f\"Epoch: {epoch} | Loss: {loss.item():.4f} | Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "0hvqk26QP6-z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(10, 2, 100, num_unique_words, epochs = 100, lr = 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlT_BGWDAIZI",
        "outputId": "9dfddace-6957-45f3-871f-8f6ded5ba5db"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 10.3358 | Test Loss: 10.3075\n",
            "Epoch: 10 | Loss: 9.9280 | Test Loss: 10.1147\n",
            "Epoch: 20 | Loss: 9.1643 | Test Loss: 9.6254\n",
            "Epoch: 30 | Loss: 7.8602 | Test Loss: 8.7513\n",
            "Epoch: 40 | Loss: 6.5099 | Test Loss: 7.9699\n",
            "Epoch: 50 | Loss: 5.5335 | Test Loss: 7.3910\n",
            "Epoch: 60 | Loss: 4.9781 | Test Loss: 7.1251\n",
            "Epoch: 70 | Loss: 4.7043 | Test Loss: 7.1450\n",
            "Epoch: 80 | Loss: 4.4459 | Test Loss: 7.1978\n",
            "Epoch: 90 | Loss: 4.1744 | Test Loss: 7.2549\n"
          ]
        }
      ]
    }
  ]
}